{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0Dy79gpjb6PtWWVGwaY+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeMinJun0102/Car_Price_Predict/blob/main/DL_test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "zrG-R45luDUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow opencv-python-headless scikit-learn matplotlib pillow\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import warnings\n",
        "from google.colab import files\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° import ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "efE45mP1uE2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 colab drive ì—°ê²°"
      ],
      "metadata": {
        "id": "3RfqvTovim7S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jsek_TCQiBpl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "print(\"ğŸ”— Google Driveì— ì—°ê²° ì¤‘...\")\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 í´ë” ìƒì„±"
      ],
      "metadata": {
        "id": "PSBIvrPhtO4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. GPU ëŸ°íƒ€ì„ í™•ì¸\n",
        "print(\"TensorFlow ë²„ì „:\", tf.__version__)\n",
        "print(\"GPU ì‚¬ìš© ê°€ëŠ¥:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# 2. í´ë” êµ¬ì¡° ìƒì„±\n",
        "os.makedirs('car_data/train', exist_ok=True)\n",
        "os.makedirs('car_data/test', exist_ok=True)\n",
        "os.makedirs('car_data/models', exist_ok=True)\n",
        "\n",
        "print(\"âœ… í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ!\")\n",
        "print(\"ë‹¤ìŒ ë‹¨ê³„: ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.\")"
      ],
      "metadata": {
        "id": "K-j1x5GyrPRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# google drive ì—°ê²°\n",
        "def google_drive():\n",
        "    # Drive ë‚´ car_data í´ë” ê²½ë¡œ\n",
        "    source_path = '/content/drive/MyDrive/itwill_Final_Project/car_data'\n",
        "\n",
        "    if source_path:\n",
        "        print(f\"ğŸ“ Drive ë‚´ ë°ì´í„° ìœ„ì¹˜ : {source_path}\")\n",
        "\n",
        "        # ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë¡œì»¬ë¡œ ë³µì‚¬\n",
        "        if os.path.exists('./car_data'):\n",
        "            shutil.rmtree('./car_data')\n",
        "\n",
        "        print(\"ğŸ“‹ ë°ì´í„°ë¥¼ ë¡œì»¬ë¡œ ë³µì‚¬ ì¤‘... (ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")\n",
        "        shutil.copytree(source_path, './car_data')\n",
        "        print(\"âœ… ë°ì´í„° ë³µì‚¬ ì™„ë£Œ!\")\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ Google Driveì—ì„œ car_data í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    check_data_structure()\n",
        "    return True\n",
        "\n",
        "# ë°ì´í„° êµ¬ì¡° í™•ì¸ í•¨ìˆ˜\n",
        "def check_data_structure():\n",
        "    \"\"\"ì—…ë¡œë“œëœ ë°ì´í„° êµ¬ì¡° í™•ì¸\"\"\"\n",
        "    print(\"\\nğŸ“Š ì—…ë¡œë“œëœ ë°ì´í„° êµ¬ì¡° í™•ì¸:\")\n",
        "\n",
        "    train_dir = 'car_data/train'\n",
        "\n",
        "    if not os.path.exists(train_dir):\n",
        "        print(\"âŒ car_data/train í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "        return False\n",
        "\n",
        "    total_images = 0\n",
        "    brands = []\n",
        "\n",
        "    for brand in os.listdir(train_dir):\n",
        "        brand_path = os.path.join(train_dir, brand)\n",
        "\n",
        "        if os.path.isdir(brand_path):\n",
        "            image_files = [f for f in os.listdir(brand_path)\n",
        "                           if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            image_count = len(image_files)\n",
        "\n",
        "            print(f\"  ğŸ“ {brand}: {image_count}ì¥\")\n",
        "            total_images += image_count\n",
        "            brands.append(brand)\n",
        "\n",
        "    print(f\"\\nâœ… ì´ {len(brands)}ê°œ ë¸Œëœë“œ, {total_images}ì¥ì˜ ì´ë¯¸ì§€\")\n",
        "\n",
        "    # ìµœì†Œ ìš”êµ¬ì‚¬í•­ ì²´í¬\n",
        "    if len(brands) < 3:\n",
        "        print(\"âš ï¸ ìµœì†Œ 3ê°œ ì´ìƒì˜ ë¸Œëœë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    if total_images < 300:\n",
        "        print(\"âš ï¸ ì „ì²´ ì´ë¯¸ì§€ê°€ 300ì¥ ë¯¸ë§Œì…ë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ ê¶Œì¥ë©ë‹ˆë‹¤.\")\n",
        "\n",
        "    return total_images > 0\n",
        "\n",
        "print(\"Google Drive ì—°ê²°\")\n",
        "google_drive()"
      ],
      "metadata": {
        "id": "GAIBkthMjR-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬"
      ],
      "metadata": {
        "id": "VUtKSx6GxJDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_data_processor_enhanced(data_dir, img_size=(224, 224)):\n",
        "    \"\"\"í–¥ìƒëœ ì „ì²˜ë¦¬ê°€ í¬í•¨ëœ ë°ì´í„° ì²˜ë¦¬\"\"\"\n",
        "\n",
        "    print(\"\\nğŸ“Š ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° ì²˜ë¦¬ ì¤‘...\")\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(\"âŒ ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "        return None, None, None\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    brand_info = {}\n",
        "    sample_images = {}\n",
        "\n",
        "    # í•œ ë²ˆì˜ ìˆœíšŒë¡œ ëª¨ë“  ì‘ì—… ì²˜ë¦¬\n",
        "    for brand in os.listdir(data_dir):\n",
        "        brand_path = os.path.join(data_dir, brand)\n",
        "\n",
        "        if os.path.isdir(brand_path):\n",
        "            print(f\"  ğŸ“ {brand} ì²˜ë¦¬ ì¤‘...\")\n",
        "            brand_count = 0\n",
        "            first_image_for_display = None\n",
        "\n",
        "            for img_file in os.listdir(brand_path):\n",
        "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img_path = os.path.join(brand_path, img_file)\n",
        "\n",
        "                    try:\n",
        "                        image = cv2.imread(img_path)\n",
        "                        if image is not None:\n",
        "                            # BGR to RGB ë³€í™˜\n",
        "                            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                            # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” ìƒ˜í”Œ í‘œì‹œìš©ìœ¼ë¡œ ì €ì¥ (ì „ì²˜ë¦¬ ì „)\n",
        "                            if first_image_for_display is None:\n",
        "                                first_image_for_display = image_rgb.copy()\n",
        "\n",
        "                            # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” (ì¡°ëª… ì •ê·œí™”)\n",
        "                            lab = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2LAB)\n",
        "                            lab[:,:,0] = cv2.equalizeHist(lab[:,:,0])  # L ì±„ë„ë§Œ í‰í™œí™”\n",
        "                            image_rgb = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "                            # ëª¨ë¸ìš© ì „ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì§• + ì •ê·œí™”)\n",
        "                            image_processed = cv2.resize(image_rgb, img_size)\n",
        "                            image_processed = image_processed.astype(np.float32) / 255.0\n",
        "\n",
        "                            images.append(image_processed)\n",
        "                            labels.append(brand)\n",
        "                            brand_count += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"    âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ {img_file}: {e}\")\n",
        "\n",
        "            # ë¸Œëœë“œë³„ ì •ë³´ ì €ì¥\n",
        "            if brand_count > 0:\n",
        "                brand_info[brand] = brand_count\n",
        "                if first_image_for_display is not None:\n",
        "                    sample_images[brand] = first_image_for_display\n",
        "\n",
        "            print(f\"    âœ… {brand}: {brand_count}ì¥ ì™„ë£Œ\")\n",
        "\n",
        "    # ë°ì´í„° êµ¬ì¡° ë¦¬í¬íŠ¸\n",
        "    total_images = sum(brand_info.values())\n",
        "    print(f\"\\nâœ… ì´ {len(brand_info)}ê°œ ë¸Œëœë“œ, {total_images}ì¥ì˜ ì´ë¯¸ì§€\")\n",
        "\n",
        "    # ìµœì†Œ ìš”êµ¬ì‚¬í•­ ì²´í¬\n",
        "    if len(brand_info) < 3:\n",
        "        print(\"âš ï¸ ìµœì†Œ 3ê°œ ì´ìƒì˜ ë¸Œëœë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "    if total_images < 300:\n",
        "        print(\"âš ï¸ ì „ì²´ ì´ë¯¸ì§€ê°€ 300ì¥ ë¯¸ë§Œì…ë‹ˆë‹¤.\")\n",
        "\n",
        "    # ìƒ˜í”Œ ì´ë¯¸ì§€ í‘œì‹œ\n",
        "    if sample_images:\n",
        "        display_samples_unified(sample_images, brand_info)\n",
        "\n",
        "    # ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ\n",
        "    if len(images) > 0:\n",
        "        images = np.array(images)\n",
        "        label_encoder = LabelEncoder()\n",
        "        encoded_labels = label_encoder.fit_transform(labels)\n",
        "        categorical_labels = to_categorical(encoded_labels)\n",
        "\n",
        "        print(f\"âœ… ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ: {len(images)}ì¥, {len(label_encoder.classes_)}ê°œ í´ë˜ìŠ¤\")\n",
        "        print(f\"âœ… í´ë˜ìŠ¤: {list(label_encoder.classes_)}\")\n",
        "\n",
        "        return images, categorical_labels, label_encoder.classes_\n",
        "\n",
        "    return None, None, None\n",
        "\n",
        "def display_samples_unified(sample_images, brand_info):\n",
        "    \"\"\"í†µí•©ëœ ìƒ˜í”Œ ì´ë¯¸ì§€ í‘œì‹œ\"\"\"\n",
        "    brands = list(sample_images.keys())\n",
        "    n_show = min(6, len(brands))\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, brand in enumerate(brands[:n_show]):\n",
        "        axes[i].imshow(sample_images[brand])\n",
        "        axes[i].set_title(f'{brand}\\n(count : {brand_info[brand]})')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    for i in range(n_show, 6):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.suptitle('Data Structure & Samples', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ì‹¤í–‰\n",
        "print(\"2ï¸âƒ£ Google Drive ì—°ê²°\")\n",
        "google_drive()\n",
        "\n",
        "# í–¥ìƒëœ ì „ì²˜ë¦¬ ì ìš©\n",
        "images, labels, class_names = complete_data_processor_enhanced('car_data/train')\n",
        "\n",
        "if images is not None:\n",
        "    print(\"\\nğŸ‰ í–¥ìƒëœ ì „ì²˜ë¦¬ë¡œ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ! ëª¨ë¸ í•™ìŠµ ì¤€ë¹„ë¨\")"
      ],
      "metadata": {
        "id": "8SSHgwWq1KH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 ëª¨ë¸ ìƒì„±"
      ],
      "metadata": {
        "id": "6mYvo_TF2aE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_car_model(num_classes, learning_rate=0.0001):\n",
        "    print(\"ëª¨ë¸ ìƒì„± ì¤‘...\")\n",
        "\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # ë ˆì´ì–´ ë™ê²° (ë§ˆì§€ë§‰ 30ê°œë§Œ í•™ìŠµ)\n",
        "    for layer in base_model.layers[:-30]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(512, activation='relu', name='feature_dense'),    # ì´ë¦„ ì¶”ê°€\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax', name='predictions')    # ì´ë¦„ ì¶”ê°€\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', 'top_k_categorical_accuracy']  # ë©”íŠ¸ë¦­ìŠ¤ ì¶”ê°€\n",
        "    )\n",
        "\n",
        "    print(f\"ëª¨ë¸ ì™„ì„±: {len(class_names)}ê°œ í´ë˜ìŠ¤\")\n",
        "    return model\n",
        "\n",
        "if 'class_names' in locals() and class_names is not None:\n",
        "    model = create_car_model(num_classes=len(class_names))\n",
        "    model.summary()\n",
        "else:\n",
        "    print('ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”')"
      ],
      "metadata": {
        "id": "n_v0UOW_0ZGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€"
      ],
      "metadata": {
        "id": "5eyaVaAd6kkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_train_model(model, images, labels, epochs=25):\n",
        "    \"\"\"ê°„ë‹¨í•œ ëª¨ë¸ í›ˆë ¨\"\"\"\n",
        "    print('í›ˆë ¨ ì‹œì‘!')\n",
        "\n",
        "    # ë°ì´í„° ë¶„í• \n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        images, labels, test_size=0.2, random_state=42,\n",
        "        stratify=labels\n",
        "    )\n",
        "\n",
        "    # ë°ì´í„° ì¦ê°•\n",
        "    train_gen = ImageDataGenerator(\n",
        "        rotation_range=15, width_shift_range=0.1, height_shift_range=0.1,\n",
        "        zoom_range=0.15, horizontal_flip=True, brightness_range=[0.8, 1.2]\n",
        "    )\n",
        "    val_gen = ImageDataGenerator()\n",
        "\n",
        "    # ì½œë°±\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4),\n",
        "        tf.keras.callbacks.ModelCheckpoint('car_data/models/best_car_model.h5', monitor='val_accuracy', save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    # í›ˆë ¨\n",
        "    history = model.fit(\n",
        "        train_gen.flow(X_train, y_train, batch_size=32),\n",
        "        steps_per_epoch=len(X_train) // 32,\n",
        "        epochs=epochs,\n",
        "        validation_data=val_gen.flow(X_val, y_val, batch_size=32),\n",
        "        validation_steps=len(X_val) // 32,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # ì‹œê°í™”\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    axes[0,0].plot(history.history['accuracy'], label='Train')\n",
        "    axes[0,0].plot(history.history['val_accuracy'], label='Val')\n",
        "    axes[0,0].set_title('Accuracy')\n",
        "    axes[0,0].legend()\n",
        "\n",
        "    axes[0,1].plot(history.history['loss'], label='Train')\n",
        "    axes[0,1].plot(history.history['val_loss'], label='Val')\n",
        "    axes[0,1].set_title('Loss')\n",
        "    axes[0,1].legend()\n",
        "\n",
        "    if 'top_k_categorical_accuracy' in history.history:\n",
        "        axes[1,0].plot(history.history['top_k_categorical_accuracy'], label='Train')\n",
        "        axes[1,0].plot(history.history['val_top_k_categorical_accuracy'], label='Val')\n",
        "        axes[1,0].set_title('Top-K Accuracy')\n",
        "        axes[1,0].legend()\n",
        "\n",
        "    axes[1,1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ê²°ê³¼ ì¶œë ¥\n",
        "    final_acc = max(history.history['val_accuracy'])\n",
        "    print(f\"ìµœê³  ê²€ì¦ ì •í™•ë„: {final_acc:.4f}\")\n",
        "\n",
        "    return history, X_val, y_val\n",
        "\n",
        "# ì‹¤í–‰\n",
        "if 'model' in locals() and 'images' in locals():\n",
        "    history, X_val, y_val = simple_train_model(model, images, labels)\n",
        "else:\n",
        "    print(\"ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ë¨¼ì € ì¤€ë¹„í•´ì£¼ì„¸ìš”.\")"
      ],
      "metadata": {
        "id": "azB8F3Nj6D1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 ìë™ì°¨ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰"
      ],
      "metadata": {
        "id": "nybh2-GEpz-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_search_system(model, class_names):\n",
        "    # Sequential ëª¨ë¸ì—ì„œ 'feature_dense' ë ˆì´ì–´ ì°¾ê¸°\n",
        "    feature_layer = None\n",
        "    for layer in model.layers:\n",
        "        if hasattr(layer, 'name') and layer.name == 'feature_dense':\n",
        "            feature_layer = layer\n",
        "            break\n",
        "\n",
        "    if feature_layer is None:\n",
        "        # ëŒ€ì•ˆ: Dense 512 ë ˆì´ì–´ ì°¾ê¸°\n",
        "        for layer in model.layers:\n",
        "            if hasattr(layer, 'units') and layer.units == 512:\n",
        "                feature_layer = layer\n",
        "                break\n",
        "\n",
        "    # feature_dense ë ˆì´ì–´ê¹Œì§€ì˜ ëª¨ë¸ ìƒì„±\n",
        "    feature_model = tf.keras.Sequential()\n",
        "    for layer in model.layers:\n",
        "        feature_model.add(layer)\n",
        "        if layer == feature_layer:\n",
        "            break\n",
        "\n",
        "    return feature_model\n",
        "\n",
        "def build_database(feature_model, images, labels):\n",
        "    print(\"ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘...\")\n",
        "    db_features = feature_model.predict(images, verbose=0)\n",
        "    db_labels = np.argmax(labels, axis=1)\n",
        "    print(f\"ì™„ë£Œ: {len(images)}ê°œ ì´ë¯¸ì§€\")\n",
        "    return db_features, db_labels, images\n",
        "\n",
        "def search_similar(query_image, feature_model, db_features, db_labels, db_images, class_names, top_k=11):\n",
        "    # ì¿¼ë¦¬ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ\n",
        "    if len(query_image.shape) == 3:\n",
        "        query_image = np.expand_dims(query_image, 0)\n",
        "    query_features = feature_model.predict(query_image, verbose=0)\n",
        "\n",
        "    # ìœ ì‚¬ë„ ê³„ì‚°\n",
        "    similarities = cosine_similarity(query_features, db_features)[0]\n",
        "    top_idx = np.argsort(similarities)[::-1][:top_k]\n",
        "\n",
        "    # ê²°ê³¼\n",
        "    results = []\n",
        "    for i, idx in enumerate(top_idx):\n",
        "        results.append({\n",
        "            'rank': i+1,\n",
        "            'car': class_names[db_labels[idx]],\n",
        "            'similarity': similarities[idx],\n",
        "            'image': db_images[idx]\n",
        "        })\n",
        "    return results\n",
        "\n",
        "def show_results(query_image, results):\n",
        "    fig, axes = plt.subplots(4, 3, figsize=(15, 8))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    axes[0].imshow(query_image.squeeze())\n",
        "    axes[0].set_title('Query')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    for i, r in enumerate(results[:11]):\n",
        "        axes[i+1].imshow(r['image'])\n",
        "        axes[i+1].set_title(f\"{r['rank']}. {r['car']}\\n{r['similarity']:.3f}\")\n",
        "        axes[i+1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ì‚¬ìš©ë²•\n",
        "if 'model' in locals() and 'images' in locals():\n",
        "    feature_model = create_search_system(model, class_names)\n",
        "    db_features, db_labels, db_images = build_database(feature_model, images, labels)\n",
        "\n",
        "    query = images[0]\n",
        "    results = search_similar(query, feature_model, db_features, db_labels, db_images, class_names)\n",
        "    show_results(query, results)\n",
        "\n",
        "    for r in results:\n",
        "        print(f\"{r['rank']}ìœ„: {r['car']} (ìœ ì‚¬ë„: {r['similarity']:.3f})\")"
      ],
      "metadata": {
        "id": "QWCziM8BvAnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "BR7Y7pjVvwV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_test():\n",
        "    \"\"\"í–¥ìƒëœ ì „ì²˜ë¦¬ê°€ í¬í•¨ëœ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸\"\"\"\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        img = cv2.imread(filename)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ ì ìš©\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "        lab[:,:,0] = cv2.equalizeHist(lab[:,:,0])\n",
        "        img = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "        processed = cv2.resize(img, (224, 224)).astype(np.float32) / 255.0\n",
        "\n",
        "        # ê²€ìƒ‰ ë° ê²°ê³¼ í‘œì‹œ\n",
        "        results = search_similar(processed, feature_model, db_features, db_labels, db_images, class_names)\n",
        "        show_results(processed, results)\n",
        "\n",
        "        print(f\"ê°€ì¥ ìœ ì‚¬í•œ ì°¨ëŸ‰: {results[0]['car']}\")\n",
        "        return processed\n",
        "    return None\n",
        "\n",
        "def batch_test(test_images, test_labels):\n",
        "    \"\"\"ì¼ê´„ í‰ê°€\"\"\"\n",
        "    correct_top1 = correct_top3 = 0\n",
        "\n",
        "    for img, label in zip(test_images, test_labels):\n",
        "        true_class = class_names[np.argmax(label)]\n",
        "        results = search_similar(img, feature_model, db_features, db_labels, db_images, class_names)\n",
        "\n",
        "        pred_classes = [r['car'] for r in results]\n",
        "        if true_class == pred_classes[0]:\n",
        "            correct_top1 += 1\n",
        "        if true_class in pred_classes[:3]:\n",
        "            correct_top3 += 1\n",
        "\n",
        "    total = len(test_images)\n",
        "    print(f\"Top-1 ì •í™•ë„: {correct_top1/total:.3f}\")\n",
        "    print(f\"Top-3 ì •í™•ë„: {correct_top3/total:.3f}\")\n",
        "\n",
        "# ì‚¬ìš©ë²•\n",
        "if 'feature_model' in locals() and 'db_features' in locals():\n",
        "    # ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
        "    upload_test()\n",
        "\n",
        "    # ê²€ì¦ ë°ì´í„° í‰ê°€\n",
        "    if 'X_val' in locals():\n",
        "        batch_test(X_val[:20], y_val[:20])"
      ],
      "metadata": {
        "id": "KD5RfbiCvBEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a0gYtb17XOHj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}