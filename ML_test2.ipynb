{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeMinJun0102/Car_Price_Predict/blob/main/ML_test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3NNIBliRdFl"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrIJF2ALQGjk"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7zTnUEP3SR1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.font_manager as fm\n",
        "import ast\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import plot_tree, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.ensemble import VotingRegressor, StackingRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, cross_validate, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "from scipy.stats import randint, uniform, loguniform\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjric-d63a5D"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJvZwnbbsm-E"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('Final.xlsx')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xN1mLaVspQb"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJDC0p9sR1Dk"
      },
      "source": [
        "# X / y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfCQ1csurffE"
      },
      "outputs": [],
      "source": [
        "X = df[['manufacturer_grouping',\n",
        "        'car_type_grouping',\n",
        "        'mileage',\n",
        "        'color_grouping',\n",
        "        'fuel_grouping',\n",
        "        'transmission_grouping',\n",
        "        'purchase_accident',\n",
        "        'sales_channel_grouping',\n",
        "        'purchase_channel_1_grouping',\n",
        "        'new_car_price',\n",
        "        'usedyear'\n",
        "       ]]\n",
        "\n",
        "y = df['residual_value_rate']\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOQeLempRxKE"
      },
      "source": [
        "# train / test 분할"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Xmt1FLy5M2B"
      },
      "outputs": [],
      "source": [
        "# train/test 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX6BMB08REUE"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리\n",
        "\n",
        "LabelEncoding 사용: LightGBM은 범주형 데이터를 직접 처리할 수 있어 OneHotEncoding보다 효율적입니다."
      ],
      "metadata": {
        "id": "q-1-CrYHMcqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['manufacturer_grouping', 'car_type_grouping', 'color_grouping',\n",
        "                        'fuel_grouping', 'transmission_grouping', 'purchase_accident',\n",
        "                        'sales_channel_grouping', 'purchase_channel_1_grouping']\n",
        "\n",
        "X_train_encoded = X_train.copy()\n",
        "X_test_encoded = X_test.copy()\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    X_train_encoded[col] = le.fit_transform(X_train[col].astype(str))\n",
        "    X_test_encoded[col] = le.transform(X_test[col].astype(str))\n",
        "    label_encoders[col] = le"
      ],
      "metadata": {
        "id": "V0MZdo4FN4f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded"
      ],
      "metadata": {
        "id": "jFdpMJ11TEJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습\n",
        "\n",
        "categorical_feature 파라미터: fit() 시 범주형 변수를 명시하여 LightGBM이 최적화된 방식으로 처리하도록 합니다."
      ],
      "metadata": {
        "id": "Xt_YEdWsP1gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm = LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 300, 500, 800],\n",
        "    'max_depth': [3, 5, 7, 10, 15, -1],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
        "    'num_leaves': [15, 31, 63, 127, 255],\n",
        "    'min_child_samples': [10, 20, 30, 50],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
        "    'reg_lambda': [0, 0.1, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=lgbm,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=500,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1, # n_jobs=-1 (모든 CPU 사용)일 때는 병렬처리로 인해 각 fold 정보가 실시간으로 출력되지 않습니다.\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"RandomizedSearchCV 실행 중...\")\n",
        "random_search.fit(\n",
        "    X_train_encoded,\n",
        "    y_train,\n",
        "    categorical_feature=categorical_features\n",
        ")\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "print(\"\\n최적 파라미터:\")\n",
        "print(random_search.best_params_)"
      ],
      "metadata": {
        "id": "3jJg1_2SP01c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 성능 평가"
      ],
      "metadata": {
        "id": "IpQYtYnnQsrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = best_model.predict(X_train_encoded)\n",
        "y_test_pred = best_model.predict(X_test_encoded)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"모델 성능 평가\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n[Train Set]\")\n",
        "print(f\"  MSE:   {train_mse:.6f}\")\n",
        "print(f\"  RMSE:  {train_rmse:.6f}\")\n",
        "print(f\"  R²:    {train_r2:.6f}\")\n",
        "\n",
        "print(f\"\\n[Test Set]\")\n",
        "print(f\"  MSE:   {test_mse:.6f}\")\n",
        "print(f\"  RMSE:  {test_rmse:.6f}\")\n",
        "print(f\"  R²:    {test_r2:.6f}\")"
      ],
      "metadata": {
        "id": "YwNSxsd2QuLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변수 중요도"
      ],
      "metadata": {
        "id": "W3G3o-fZQwop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train_encoded.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"변수 중요도\")\n",
        "print(\"=\"*50)\n",
        "print(importance_df)"
      ],
      "metadata": {
        "id": "aBo-BuQ2QySU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfSZY4GDOLN4"
      },
      "source": [
        "# CatBoostRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리\n",
        "\n",
        "전처리가 더 간단: LGBM처럼 LabelEncoder도 필요 없고, 범주형 변수를 str 타입으로만 변환하면 CatBoost가 알아서 최적 처리합니다."
      ],
      "metadata": {
        "id": "0WCzxpSsTRbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['manufacturer_grouping', 'car_type_grouping', 'color_grouping',\n",
        "                        'fuel_grouping', 'transmission_grouping', 'purchase_accident',\n",
        "                        'sales_channel_grouping', 'purchase_channel_1_grouping']\n",
        "\n",
        "# 범주형 변수를 str 타입으로만 변환\n",
        "X_train_cat = X_train.copy()\n",
        "X_test_cat = X_test.copy()\n",
        "\n",
        "for col in categorical_features:\n",
        "    X_train_cat[col] = X_train_cat[col].astype(str)\n",
        "    X_test_cat[col] = X_test_cat[col].astype(str)\n",
        "\n",
        "# 범주형 변수의 인덱스 찾기\n",
        "cat_features_idx = [X_train_cat.columns.get_loc(col) for col in categorical_features]"
      ],
      "metadata": {
        "id": "OO_7F5VYTRD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습\n",
        "\n",
        "cat_features 파라미터: 범주형 변수의 인덱스를 지정하면 CatBoost가 내부적으로 Target Encoding 등을 자동 적용합니다"
      ],
      "metadata": {
        "id": "AxSuAs9yTV_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catboost = CatBoostRegressor(\n",
        "    random_state=42,\n",
        "    verbose=0,\n",
        "    cat_features=cat_features_idx  # 범주형 변수 인덱스 지정\n",
        ")\n",
        "\n",
        "param_distributions = {\n",
        "    'iterations': [100, 200, 300, 500, 800],\n",
        "    'depth': [3, 5, 7, 10],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
        "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
        "    'border_count': [32, 64, 128, 255],\n",
        "    'bagging_temperature': [0, 0.5, 1.0],\n",
        "    'random_strength': [0, 1, 2],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=catboost,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=500,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"RandomizedSearchCV 실행 중...\")\n",
        "random_search.fit(X_train_cat, y_train)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "print(\"\\n최적 파라미터:\")\n",
        "print(random_search.best_params_)"
      ],
      "metadata": {
        "id": "YjnVdXZlTXWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 성능 평가"
      ],
      "metadata": {
        "id": "blM5ewTFTc3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = best_model.predict(X_train_cat)\n",
        "y_test_pred = best_model.predict(X_test_cat)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"모델 성능 평가\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n[Train Set]\")\n",
        "print(f\"  MSE:   {train_mse:.6f}\")\n",
        "print(f\"  RMSE:  {train_rmse:.6f}\")\n",
        "print(f\"  R²:    {train_r2:.6f}\")\n",
        "\n",
        "print(f\"\\n[Test Set]\")\n",
        "print(f\"  MSE:   {test_mse:.6f}\")\n",
        "print(f\"  RMSE:  {test_rmse:.6f}\")\n",
        "print(f\"  R²:    {test_r2:.6f}\")"
      ],
      "metadata": {
        "id": "FZmXT7JyTfK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변수 중요도"
      ],
      "metadata": {
        "id": "p_7y0ytYThE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train_cat.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"변수 중요도\")\n",
        "print(\"=\"*50)\n",
        "print(importance_df)"
      ],
      "metadata": {
        "id": "olibcxpnTiF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CatBoostRegressor2"
      ],
      "metadata": {
        "id": "SjDdC9p7swFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리"
      ],
      "metadata": {
        "id": "9SjhV7kGs1T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['manufacturer_grouping', 'car_type_grouping', 'color_grouping',\n",
        "                        'fuel_grouping', 'transmission_grouping', 'purchase_accident',\n",
        "                        'sales_channel_grouping', 'purchase_channel_1_grouping']\n",
        "\n",
        "X_train_cat = X_train.copy()\n",
        "X_test_cat = X_test.copy()\n",
        "\n",
        "for col in categorical_features:\n",
        "    X_train_cat[col] = X_train_cat[col].astype(str)\n",
        "    X_test_cat[col] = X_test_cat[col].astype(str)\n",
        "\n",
        "cat_features_idx = [X_train_cat.columns.get_loc(col) for col in categorical_features]"
      ],
      "metadata": {
        "id": "_iQglY9etCal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "BNljoGkYs2vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# catboost = CatBoostRegressor(\n",
        "#     random_state=42,\n",
        "#     verbose=0,\n",
        "#     cat_features=cat_features_idx\n",
        "# )\n",
        "\n",
        "# # border_count 제거 (max_bin만 사용)\n",
        "# param_distributions = {\n",
        "#     'iterations': [500, 800, 1000, 1500, 2000],\n",
        "#     'depth': [4, 5, 6, 7, 8, 9, 10],\n",
        "#     'learning_rate': [0.01, 0.03, 0.05, 0.07, 0.1, 0.15],\n",
        "#     'l2_leaf_reg': [1, 3, 5, 7, 9, 11, 15],\n",
        "#     'random_strength': [0, 0.5, 1, 1.5, 2],\n",
        "\n",
        "#     # max_bin만 사용 (border_count와 동일한 역할)\n",
        "#     'max_bin': [32, 64, 128, 254, 512],\n",
        "\n",
        "#     # bootstrap 관련 파라미터\n",
        "#     'bootstrap_type': ['Bayesian', 'Bernoulli', 'MVS'],\n",
        "#     'bagging_temperature': [0, 0.3, 0.5, 0.7, 1.0],\n",
        "#     'subsample': [0.7, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
        "\n",
        "#     # 추가 파라미터\n",
        "#     'min_data_in_leaf': [1, 5, 10, 20, 30],\n",
        "#     'one_hot_max_size': [2, 5, 10],\n",
        "#     'rsm': [0.7, 0.8, 0.9, 1.0],\n",
        "#     'leaf_estimation_iterations': [1, 5, 10]\n",
        "# }\n",
        "\n",
        "# random_search = RandomizedSearchCV(\n",
        "#     estimator=catboost,\n",
        "#     param_distributions=param_distributions,\n",
        "#     n_iter=500,\n",
        "#     cv=5,\n",
        "#     scoring='neg_mean_squared_error',\n",
        "#     n_jobs=-1,\n",
        "#     random_state=42,\n",
        "#     verbose=2\n",
        "# )\n",
        "\n",
        "# print(\"RandomizedSearchCV 실행 중...\")\n",
        "# random_search.fit(X_train_cat, y_train)\n",
        "\n",
        "# best_model = random_search.best_estimator_\n",
        "# print(\"\\n최적 파라미터:\")\n",
        "# print(random_search.best_params_)"
      ],
      "metadata": {
        "id": "8F8U3qZGtDDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. RandomizedSearchCV로 최적 파라미터 찾기\n",
        "catboost = CatBoostRegressor(\n",
        "    random_state=42,\n",
        "    verbose=0,\n",
        "    cat_features=cat_features_idx\n",
        ")\n",
        "\n",
        "param_distributions = {\n",
        "    'iterations': [500, 800, 1000, 1500, 2000],\n",
        "    'depth': [4, 5, 6, 7, 8, 9, 10],\n",
        "    'learning_rate': [0.01, 0.03, 0.05, 0.07, 0.1, 0.15],\n",
        "    'l2_leaf_reg': [1, 3, 5, 7, 9, 11, 15],\n",
        "    'random_strength': [0, 0.5, 1, 1.5, 2],\n",
        "    'max_bin': [32, 64, 128, 254, 512],\n",
        "    'bootstrap_type': ['Bayesian', 'Bernoulli', 'MVS'],\n",
        "    'bagging_temperature': [0, 0.3, 0.5, 0.7, 1.0],\n",
        "    'subsample': [0.7, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
        "    'min_data_in_leaf': [1, 5, 10, 20, 30],\n",
        "    'one_hot_max_size': [2, 5, 10],\n",
        "    'rsm': [0.7, 0.8, 0.9, 1.0],\n",
        "    'leaf_estimation_iterations': [1, 5, 10]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=catboost,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=500,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"RandomizedSearchCV 실행 중...\")\n",
        "random_search.fit(X_train_cat, y_train)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "print(\"\\n최적 파라미터:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "# 2. 최적 모델로 다시 학습 (학습 과정 기록하면서)\n",
        "print(\"\\n학습 과정 시각화를 위해 최적 모델 재학습 중...\")\n",
        "\n",
        "final_model = CatBoostRegressor(\n",
        "    **random_search.best_params_,\n",
        "    random_state=42,\n",
        "    cat_features=cat_features_idx,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# eval_set으로 검증 데이터 전달\n",
        "final_model.fit(\n",
        "    X_train_cat, y_train,\n",
        "    eval_set=(X_test_cat, y_test),\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# 3. 학습 기록 가져오기\n",
        "train_loss = final_model.evals_result_['learn']['RMSE']\n",
        "test_loss = final_model.evals_result_['validation']['RMSE']\n",
        "\n",
        "# 4. R² 계산 (매 10 epoch마다만 계산 - 속도 향상)\n",
        "epochs = range(0, len(train_loss), 10)  # 10 epoch마다\n",
        "train_r2_history = []\n",
        "test_r2_history = []\n",
        "\n",
        "print(\"R² 계산 중...\")\n",
        "for i in epochs:\n",
        "    y_train_pred = final_model.predict(X_train_cat, ntree_end=i+1)\n",
        "    y_test_pred = final_model.predict(X_test_cat, ntree_end=i+1)\n",
        "\n",
        "    train_r2_history.append(r2_score(y_train, y_train_pred))\n",
        "    test_r2_history.append(r2_score(y_test, y_test_pred))\n",
        "\n",
        "# 5. 그래프 그리기\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy (R²) 그래프\n",
        "ax1.plot(list(epochs), train_r2_history, label='Train', color='#1f77b4', linewidth=2)\n",
        "ax1.plot(list(epochs), test_r2_history, label='Test', color='#ff7f0e', linewidth=2)\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Accuracy (R²)', fontsize=12)\n",
        "ax1.set_title('Accuracy', fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim([0.85, 1.0])  # R² 범위 조정\n",
        "\n",
        "# Loss (RMSE) 그래프\n",
        "ax2.plot(train_loss, label='Train', color='#1f77b4', linewidth=2)\n",
        "ax2.plot(test_loss, label='Test', color='#ff7f0e', linewidth=2)\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Loss (RMSE)', fontsize=12)\n",
        "ax2.set_title('Loss', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 6. 최종 성능 평가\n",
        "y_train_pred = final_model.predict(X_train_cat)\n",
        "y_test_pred = final_model.predict(X_test_cat)\n",
        "\n",
        "train_r2_final = r2_score(y_train, y_train_pred)\n",
        "test_r2_final = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"최종 모델 성능 평가\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n[Train Set]\")\n",
        "print(f\"  R²:    {train_r2_final:.3f} ({train_r2_final*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n[Test Set]\")\n",
        "print(f\"  R²:    {test_r2_final:.3f} ({test_r2_final*100:.1f}%)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# best_model을 final_model로 업데이트\n",
        "best_model = final_model"
      ],
      "metadata": {
        "id": "LNWTve5iZ4LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 성능 평가"
      ],
      "metadata": {
        "id": "-cpLIKC8s4Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train_pred = best_model.predict(X_train_cat)\n",
        "# y_test_pred = best_model.predict(X_test_cat)\n",
        "\n",
        "# train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "# train_rmse = np.sqrt(train_mse)\n",
        "# train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "# test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "# test_rmse = np.sqrt(test_mse)\n",
        "# test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# print(\"\\n\" + \"=\"*50)\n",
        "# print(\"모델 성능 평가\")\n",
        "# print(\"=\"*50)\n",
        "# print(f\"\\n[Train Set]\")\n",
        "# print(f\"  MSE:   {train_mse:.3f}\")\n",
        "# print(f\"  RMSE:  {train_rmse:.3f}\")\n",
        "# print(f\"  R²:    {train_r2:.3f}\")\n",
        "\n",
        "# print(f\"\\n[Test Set]\")\n",
        "# print(f\"  MSE:   {test_mse:.3f}\")\n",
        "# print(f\"  RMSE:  {test_rmse:.3f}\")\n",
        "# print(f\"  R²:    {test_r2:.3f}\")"
      ],
      "metadata": {
        "id": "KPaJdiPItHW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = best_model.predict(X_train_cat)\n",
        "y_test_pred = best_model.predict(X_test_cat)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"모델 성능 평가\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n[Train Set]\")\n",
        "print(f\"  MSE:   {train_mse:.3f}\")\n",
        "print(f\"  RMSE:  {train_rmse:.3f}\")\n",
        "print(f\"  R²:    {train_r2:.3f}\")\n",
        "\n",
        "print(f\"\\n[Test Set]\")\n",
        "print(f\"  MSE:   {test_mse:.3f}\")\n",
        "print(f\"  RMSE:  {test_rmse:.3f}\")\n",
        "print(f\"  R²:    {test_r2:.3f}\")"
      ],
      "metadata": {
        "id": "ZYSY9rW_ablC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변수 중요도"
      ],
      "metadata": {
        "id": "4ZBQ2RJ6s5vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importance_df = pd.DataFrame({\n",
        "#     'Feature': X_train_cat.columns,\n",
        "#     'Importance': best_model.feature_importances_\n",
        "# }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# print(\"\\n\" + \"=\"*50)\n",
        "# print(\"변수 중요도\")\n",
        "# print(\"=\"*50)\n",
        "# print(importance_df)"
      ],
      "metadata": {
        "id": "QVlYSwQStI_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train_cat.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"변수 중요도\")\n",
        "print(\"=\"*50)\n",
        "print(importance_df)"
      ],
      "metadata": {
        "id": "jXiadQViriQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CatBoostRegressor3"
      ],
      "metadata": {
        "id": "zvZ8wUx2ZuSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리\n",
        "\n",
        "피처 엔지니어링 - 기존 데이터를 조합/변환해서 새로운 변수를 만드는 작업\n",
        "\n",
        "<파생 변수 생성, 변수 변환, 변수 선택, 변수 결합, 차원 축소>"
      ],
      "metadata": {
        "id": "KJ1GBfCDZxcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['manufacturer_grouping', 'car_type_grouping', 'color_grouping',\n",
        "                        'fuel_grouping', 'transmission_grouping', 'purchase_accident',\n",
        "                        'sales_channel_grouping', 'purchase_channel_1_grouping']\n",
        "\n",
        "X_train_cat = X_train.copy()\n",
        "X_test_cat = X_test.copy()\n",
        "\n",
        "# 범주형 변수 str 변환\n",
        "for col in categorical_features:\n",
        "    X_train_cat[col] = X_train_cat[col].astype(str)\n",
        "    X_test_cat[col] = X_test_cat[col].astype(str)\n",
        "\n",
        "# 파생 변수 추가\n",
        "X_train_cat['mileage_per_year'] = X_train_cat['mileage'] / (X_train_cat['usedyear'] + 1)\n",
        "X_test_cat['mileage_per_year'] = X_test_cat['mileage'] / (X_test_cat['usedyear'] + 1)\n",
        "\n",
        "cat_features_idx = [X_train_cat.columns.get_loc(col) for col in categorical_features]"
      ],
      "metadata": {
        "id": "-h2NYHysZ3k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "ms0zK37cZxX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catboost = CatBoostRegressor(\n",
        "    random_state=42,\n",
        "    verbose=0,\n",
        "    cat_features=cat_features_idx\n",
        ")\n",
        "\n",
        "# border_count 제거 (max_bin만 사용)\n",
        "param_distributions = {\n",
        "    'iterations': [500, 800, 1000, 1500, 2000],\n",
        "    'depth': [4, 5, 6, 7, 8, 9, 10],\n",
        "    'learning_rate': [0.01, 0.03, 0.05, 0.07, 0.1, 0.15],\n",
        "    'l2_leaf_reg': [1, 3, 5, 7, 9, 11, 15],\n",
        "    'random_strength': [0, 0.5, 1, 1.5, 2],\n",
        "\n",
        "    # max_bin만 사용 (border_count와 동일한 역할)\n",
        "    'max_bin': [32, 64, 128, 254, 512],\n",
        "\n",
        "    # bootstrap 관련 파라미터\n",
        "    'bootstrap_type': ['Bayesian', 'Bernoulli', 'MVS'],\n",
        "    'bagging_temperature': [0, 0.3, 0.5, 0.7, 1.0],\n",
        "    'subsample': [0.7, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
        "\n",
        "    # 추가 파라미터\n",
        "    'min_data_in_leaf': [1, 5, 10, 20, 30],\n",
        "    'one_hot_max_size': [2, 5, 10],\n",
        "    'rsm': [0.7, 0.8, 0.9, 1.0],\n",
        "    'leaf_estimation_iterations': [1, 5, 10]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=catboost,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=500,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"RandomizedSearchCV 실행 중...\")\n",
        "random_search.fit(X_train_cat, y_train)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "print(\"\\n최적 파라미터:\")\n",
        "print(random_search.best_params_)"
      ],
      "metadata": {
        "id": "oHKzxn13Z81T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 성능 평가"
      ],
      "metadata": {
        "id": "edZEThToZxRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = best_model.predict(X_train_cat)\n",
        "y_test_pred = best_model.predict(X_test_cat)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"모델 성능 평가\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n[Train Set]\")\n",
        "print(f\"  MSE:   {train_mse:.3f}\")\n",
        "print(f\"  RMSE:  {train_rmse:.3f}\")\n",
        "print(f\"  R²:    {train_r2:.3f}\")\n",
        "\n",
        "print(f\"\\n[Test Set]\")\n",
        "print(f\"  MSE:   {test_mse:.3f}\")\n",
        "print(f\"  RMSE:  {test_rmse:.3f}\")\n",
        "print(f\"  R²:    {test_r2:.3f}\")"
      ],
      "metadata": {
        "id": "vCZJODKdaAMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변수 중요도"
      ],
      "metadata": {
        "id": "D_aQ9pu4ZwtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train_cat.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"변수 중요도\")\n",
        "print(\"=\"*50)\n",
        "print(importance_df)"
      ],
      "metadata": {
        "id": "a-2jmlSVaCIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJKqLRKAxsN3"
      },
      "source": [
        "# GradiantBoosting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리\n",
        "\n",
        "전처리: LightGBM, CatBoost와 달리 범주형 변수를 자동 처리하지 못해서 LabelEncoding 필수입니다."
      ],
      "metadata": {
        "id": "ln8u665VT14X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['manufacturer_grouping', 'car_type_grouping', 'color_grouping',\n",
        "                        'fuel_grouping', 'transmission_grouping', 'purchase_accident',\n",
        "                        'sales_channel_grouping', 'purchase_channel_1_grouping']\n",
        "\n",
        "X_train_encoded = X_train.copy()\n",
        "X_test_encoded = X_test.copy()\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    X_train_encoded[col] = le.fit_transform(X_train[col].astype(str))\n",
        "    X_test_encoded[col] = le.transform(X_test[col].astype(str))\n",
        "    label_encoders[col] = le"
      ],
      "metadata": {
        "id": "7IJUKnzHT20V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습\n",
        "\n",
        "sklearn 기본 모델: 별도 라이브러리 설치 없이 사용 가능하지만, LightGBM/CatBoost보다 속도가 느립니다."
      ],
      "metadata": {
        "id": "FZJqeuPYT5_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'max_features': ['sqrt', 'log2', None, 0.5, 0.8],\n",
        "    'loss': ['squared_error', 'huber', 'absolute_error']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=gb,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=500,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"RandomizedSearchCV 실행 중...\")\n",
        "random_search.fit(X_train_encoded, y_train)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "print(\"\\n최적 파라미터:\")\n",
        "print(random_search.best_params_)"
      ],
      "metadata": {
        "id": "Txf5qGZ0T7J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 성능 평가"
      ],
      "metadata": {
        "id": "e2mrmYx_T9gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = best_model.predict(X_train_encoded)\n",
        "y_test_pred = best_model.predict(X_test_encoded)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"모델 성능 평가\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n[Train Set]\")\n",
        "print(f\"  MSE:   {train_mse:.6f}\")\n",
        "print(f\"  RMSE:  {train_rmse:.6f}\")\n",
        "print(f\"  R²:    {train_r2:.6f}\")\n",
        "\n",
        "print(f\"\\n[Test Set]\")\n",
        "print(f\"  MSE:   {test_mse:.6f}\")\n",
        "print(f\"  RMSE:  {test_rmse:.6f}\")\n",
        "print(f\"  R²:    {test_r2:.6f}\")"
      ],
      "metadata": {
        "id": "cD8uDPmyT-gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변수 중요도"
      ],
      "metadata": {
        "id": "39vjpKpCUBNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train_encoded.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"변수 중요도\")\n",
        "print(\"=\"*50)\n",
        "print(importance_df)"
      ],
      "metadata": {
        "id": "8kbyNvrsUCyK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}